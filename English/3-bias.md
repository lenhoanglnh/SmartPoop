# 3. The turd bias

> True comfort is not just knowing that you can relieve yourself safely; it is knowing that your health will be taken care of at all times thanks to the intelligence of your toilet. SmartToilets[^smarttoilets] from SmartPoop. Let us take care of you.

[^smarttoilets]: SmartToilets are already in development! They even led to an academic publication, with a prototype capable of... rectal recognition!  
[**Paper.** A mountable toilet system for personalized health monitoring via the analysis of excreta. Seung-min Park et al. Nature Biomedical Engineering (2020).](https://www.nature.com/articles/s41551-020-0534-9)

This is the fifth time today that Issa Gueye has seen this ad on his phone. Ironically, this time, he is sitting on the toilet[^toilets], between two videos of comedians, that he is exposed to it. A few minutes later, when he opens the SmartPoop application to film his excrement, he realizes that installing SmartToilets would save him the trouble of filming the turds himself. Even though he's been doing it almost daily for three years now, he still finds the effort laborious and repulsive.

[^toilets]: The invention of toilets, and in particular sewage systems, was in fact one of the great advances in the history of civilization, as it effectively fought the spread of many diseases such as cholera. In fact, more than 2 billion people still do not have access to it. It is estimated that, because of this, about 800,000 children die every year from diarrhea.  
[**Video.** How The Toilet Changed History. It's Okay to Be Smart (2017).](https://www.youtube.com/watch?v=GWQG1YZS9l4)

Issa, the avid sportsman who likes to track his fitness, then clicks on the special offer offered by his app. As a regular user since the beginning of SmartPoop, he indeed has a 30% discount on the purchase of a basic SmartToilet, for a total price of 12,000 euros. It's expensive, but this finance trader can afford it. In fact, Issa then discovered the existence of a SmartToilet Deluxe version. This version allows pre-heating of the bowl, odor filtration by ceramic honeycomb filter, cleaning by fine water jet and drying by hot air, all optimized by artificial intelligence algorithms to maximize the user's well-being[^toilet-japanese]. Intrigued, Issa opts for this product, despite its exorbitant price of 25,000 euros.

[^toilet-japanese]: In Japan, toilets often have several of these features.  
[**Video.** Why You Need to Try a High-Tech Japanese Toilet. Lifehacker (2019).](https://www.youtube.com/watch?v=GZRwI7m7gnw)

### Poo

A few days later, SmartPoop's SmartToilet Deluxe is delivered and installed at Issa's home. That evening, Issa went to test his new toilet with a big smile and some hesitation. As he approaches the toilet, the lid opens automatically. Issa then sits down on the bowl. A strange feeling of warmth accompanies his contact with the bowl. "It's like I'm using the toilet right after someone else... Not very reassuring. But I should probably just get used to it," he says to himself.

> Hello Issa," says a male voice.

Issa is startled. The toilet has just spoken to him!

> Relax and enjoy the comfort of the SmartToilet Deluxe," she explains. I'm Poo, your voice assistant. Would you prefer I use a female voice[^female-voice]?

[^female-voice]: After many criticisms about reinforcing gender bias, Apple decided to give Siri a male voice by default.  
[**Journal.** How AI bots and voice assistants reinforce gender bias. Caitlin Chin and Mishaela Robison. Brookings (2020).](https://www.brookings.edu/research/how-ai-bots-and-voice-assistants-reinforce-gender-bias/)  
[**Journal.** Apple's Siri is no longer a woman by default, but is this really a win for feminism?. Eleonore Fournier-Tombs. The Conversation (2021).](https://theconversation.com/apples-siri-is-no-longer-a-woman-by-default-but-is-this-really-a-win-for-feminism-164030)

Issa is very disturbed. After a few seconds, he answers: "Yes, I prefer a female voice.

> "Feel free to tell me how you feel so I can optimize your comfort," says Poo, now with a female voice[^individual-societal].

[^individual-societal]: This example highlights the tension between users' control over the technologies they use and the consequences that this control can have on a social scale. Thus, by allowing the user to customize their technologies, there is a risk that they aggravate, consciously or not, gender bias (in this case), hate speech or misinformation. In the end, this tension resides in John Stuart Mill's harm principle; or more simply put, in the principle "the freedoms of some end where those of others begin".  
[**Video.** The Harm Principle: How to live your life the way you want to. BBC Radio 4 (2014).](https://www.youtube.com/watch?v=R9IM3ZKNMCk)

Disturbed, Issa remains silent for a few more seconds. He finally replies: "Perhaps we can start by being on a first-name basis.

> With pleasure, Issa. I am at your service.

Issa's phone suddenly vibrates. He picks it up. It reads: "Congratulations! You are now using our SmartToilet Deluxe. We wish you a pleasant experience". Still tense, Issa finds it hard to let go.

> The first time is never easy. But relax. Try to enjoy your new daily comfort.

> I'm not used to talking to a voice assistant in the toilet!

> I understand. I'm not yet used to talking to toilet users either!

Little by little, however, Issa is increasingly perceiving his SmartToilets as an important new comfort[^new-toilets]. After all, put together, humans spend an enormous amount of time sitting on a toilet. Might as well make a good time of it!

[^new-toilets]: Billions of humans on earth don't have access to this comfort. As we have seen, this poses serious health problems.  
[**Video.** 6 Toilets From History, and What They Taught Us. SciShow (2021).](https://www.youtube.com/watch?v=kTqDmkTh0IY)
But research is developing solutions to make this comfort available to more people, including innovations in excreta treatment.  
[**Video.** 3 Groundbreaking New Toilets. SciShow (2018).](https://www.youtube.com/watch?v=FaLZUJAAgnk)

Finally, Issa moves on with his task.

> Uh... Issa says, with some hesitation. Are you... analyzing it?

> Yes Issa, I am filming your "data" from different angles, and putting the videos on your online account. I am also taking other samples for further analysis. Do you want to know more?

> Yes, tell me more.

> With pleasure. The water in which the excreta is bathed is also constantly sampled and analyzed by spectroscopy. In other words, we study the way this water absorbs different colors of the light spectrum, in a very precise way. This allows us to identify certain molecules within your feces, which enables us to do a much more accurate health check-up[^spectroscopy]. We also perform mass spectrometry[^spectrometry], and chemical measurements, for example of the acidity of this water[^pH].

[^spectroscopy]: [**Video.** Spectrophotometry and Beer's Law. Professor Dave Explains (2019).](https://www.youtube.com/watch?v=zuUvQN8KXOk)

[^spectrometry]: Mass spectrometry involves slicing a molecule to be analyzed into charged sub-molecules, for example using electron ionization, and measuring the ability of a magnetic field to deflect the path of sub-molecules. Since heavier submolecules are harder to deflect, this gives us information on the mass of these submolecules, and thus on the mass and composition of the molecule to be analyzed.  
[**Video.** IR Spectroscopy and Mass Spectrometry: Crash Course Organic Chemistry #5 (2020).](https://www.youtube.com/watch?v=xMa1BQ8z9C0)

[^pH]: The acidity of a liquid is measured by its pH, typically via electrical measurements.  
[How a pH meter works! pH Professor (2017).](https://www.youtube.com/watch?v=PBTn4gTEbkU)

> When will I have results?

> I'll keep you posted, in the bathroom or in your app, if there are any measurements of concern.

### "Very concerning."

A few days later, when he has just returned home after a hard day's work. Issa receives a notification from SmartPoop. Issa then asks, "Poo, what's going on?"

> I've been running some very concerning tests. Issa, I think you should go to the hospital.

Terrified, Issa leaves his house, gets into his car and drives straight to the hospital. When he arrives at the emergency room, he asks to see a doctor. "For what reason?" he id asked. "I got an alert from SmartPoop, which just told me to come to the emergency room," Issa explains.

After a minute or two, Issa is taken care of.

> Hello Issa, I'm Dr. Paola Marta. You should know that we are used to dealing with SmartPoop emergencies. For the past two years, most of our patients have come in as a result of a SmartPoop alert, and the report they send us always helps us a lot in caring for our patients[^familiarity]. How do you feel?

[^familiarity]: According to a recent study, most people do indeed seem to trust an algorithm's judgments more than a human's, at least for some predictions like Tesla's success, European sanctions against cyberwarfare, or the future of Brexit. Disturbingly, however, experienced professionals, on the other hand, trust algorithms less, leading them to worse judgments than non-professionals when given an algorithmic advice!  
[**Paper.** Algorithm appreciation: People prefer algorithmic to human judgment. Jennifer Logg, Julia Minsona & Don Moore. Organizational Behavior and Human Decision Processes (2019).](https://www.sciencedirect.com/science/article/abs/pii/S0749597818303388)  
Having said this, psychological research also suggests that what is familiar to us seems more believable, and sometimes disturbingly so. This is known as *familiarity bias*. For example, a subject who is repeatedly exposed to the phrase "the body temperature of a chicken" has a greater probability of judging the phrase "the body temperature of a chicken is 34°C" to be true. The fact that Dr. Paola Marta interacts daily with SmartPoop reports, which are also effective in guiding her in the treatment of her patients, could then explain why Dr. Paola Marta trusts SmartPoop.  
[**Video.** The Illusion of Truth. Veritasium (2016).](https://www.youtube.com/watch?v=cebFWOlx848)

> So far, all I have is a stomach ache. But I'm pretty terrified. SmartPoop says my condition is "very concerning."

> Very concerning, you say?

> Yes. Doctor, do you know what's wrong with me and if I'll be okay?

Dr. Marta looks away from Issa. Clearly embarrassed, Dr. Marta seems terrified by SmartPoop's diagnosis. She has had 27 patients whose condition were deemed "of great concern" by SmartPoop. All died[^laplace-succession]. After an interminable silence, Dr. Marta finally answered, obviously with an effort to sound as reassuring as possible, despite the circumstances.

[^laplace-succession]: Laplace's law of succession suggests that, if one had a priori total initial uncertainty that a "very concerning" SmartPoop diagnosis led to a life-threatening condition, then, knowing that the first 27 patients with that diagnosis all died, the probability that Issa would in turn die would then be 28/29. This fully justifies Dr. Marta's fear.  
[**Video.** Binomial distributions | Probabilities of probabilities, part 1. 3Blue1Brown (2020).](https://www.youtube.com/watch?v=8idr1WZ1A7Q)

> I promise you that we will do our best.

After a blood test, Issa finally finds himself lying in a hospital bed, alone, abandoned to his own imagination. He fears the worst. He thinks of all the things he would have liked to have done. Issa harbors regrets, and contemplates his posterity. All his life, Issa has only followed the lure of gain. He was told that to succeed in finance is to roll in gold and triumph in life. This is what he did. Does it make him a bad person[^growth-mindset]?

[^growth-mindset]: Empirical psychology suggests that self-labeling can give an impression of permanence of some of our properties, which can then be very detrimental to our personal development. This is called a "fixed mindset". In contrast, people who think they can grow (*growth mindset*) seem to be much more fulfilled. Therefore, rather than calling oneself a "bad person", it would seem more appropriate to call oneself a "person who has done some bad things", or even a "person who aspires to do better things".  
[**Video.** The power of believing that you can improve | Carol Dweck. TED (2014).](https://www.youtube.com/watch?v=_X0mgOOSpLU)  
[**Book.** Mindset: The New Psychology of Success. Carol Dweck. Penguin (2007).](https://www.penguinrandomhouse.com/books/44330/mindset-by-carol-s-dweck-phd/)

Certainly, his career has at least allowed him to afford all sorts of luxury gear, like SmartToilets Deluxes. The ultimate proof of social success. But has Issa really accomplished anything in his life? What about all those other people who have suffered because of him? What about his ex-wife, whom he abandoned? Of his children with whom he spent so little time[^goal-factoring]?

[^goal-factoring]: These questions refer to what some people call *goal factoring* or *self alignment*, which involves asking ourselves whether the goals we have set are really the goals we would really like to set for ourselves.  
[**Blog.** Goal Factoring. LessWrong (2018).](https://www.lesswrong.com/posts/Cu5C5KhkoXhrPMLFN/goal-factoring)  
Indeed, it often seems to be the case that these goals are *orphan beliefs*, i.e. goals that we set as a result of fundamental motivations, and that we persist in setting even though these fundamental motivations have disappeared. Typically, we may have wanted to please our parents, at a time when our parents' pride was very important to us; but upon reflection, we came to realize that other fundamental motivations prevailed over that, like, say, actually making the world a better place.  
[**Video.** Your brain is not a Bayes net (and why that matters). Julia Galef (2016).](https://www.youtube.com/watch?v=cFv5DvrLDCg)

Dr. Marta then turns back to Issa. "Finally," Issa exclaims inwardly, feeling as if he has been abandoned for several hours, even though Dr. Marta has only been gone for ten minutes[^time-subjective]. Dr. Marta then asks Issa to accompany her for an X-ray, and tells him that a colonoscopy is also being considered. In the space of a few hours, Issa will in fact undergo all sorts of analyses. At the end of the day, Dr. Marta tells him that he will stay overnight for observation. She encourages him to try to eat the meal that is served to him, and to try to get some sleep to rest.

[^time-subjective]: [**Video.** How Your Brain Makes Time Pass Fast or Slow. It's Okay To Be Smart (2020).](https://www.youtube.com/watch?v=NSy0Z7XCF3E)

The next morning, Dr. Marta finally arrives in Issa's room. Issa is exhausted. Terrified, he has not slept all night.

> What is the news, doctor?

> You clearly have very advanced fatigue and a high level of stress, with obvious digestive and sleep problems. Something is wrong. However, all our measurements still fail to identify the origin of your problems. We have called SmartPoop, whose health report is not really in line with our review. They are in the process of manually analyzing your data. We're hoping that together we'll be able to pinpoint the problem. But this is going to take us some time. I'm sorry about that. I'm so sorry.

### SmartPoop Alert

At the end of the morning, it's Marc's turn to enter Katia's office.

> We have a problem, he says.

> What's going on, Marc?

> My assistant just told me that a doctor, Dr. Marta, kept trying to reach us last night and this morning. She has a patient whom SmartPoop told to go to the emergency room. They've run a lot of tests on the patient. But they can't figure out what's causing the problem.

> Did you get the diagnostics team on the problem?

> Yes. They've been working since 9:00 this morning, and they still can't find the problem. They asked me to ask you to take a look at the data.

> Are you sure it's my job to look? I'm very busy. I have to prepare for SmartPoopCon 2024 this weekend.

> They have an idea of the problem, but they want your expertise to confirm their intuition...

> Can you send me the case references?

> It's already done.

Katia then opens her email client, which tells her that she has 25,251 unread messages. She sorts her messages by recipient and finds the one from Marc[^externalization-memory]. Katia copies and pastes the case references, and runs queries to the SmartPoop database. She then retrieves Issa's data, and analyzes the statistics of his excrements. Katia executes some commands, which then generate all kinds of graphs. After seeing about fifteen graphs, Katia exclaims: "Oh no! Issa is out of distribution[^hors-distribution]".

[^externalization-memory]: The philosopher Michel Serres liked to insist on the impact of information technologies, such as paper, printing or computers, on the *externalization* of our cognition. In this regard, it is remarkable to note to what extent our email boxes have managed to externalize a large part of our memory. In a sense, our email boxes know us much better than we know ourselves, not because they are "intelligent", but simply because their memory is much more reliable than human memory, and because searching in these email boxes is often much more efficient than searching in our memory.  
[**Video.**  Michel Serres - Les nouvelles technologies : révolution culturelle et cognitive. I Moved to Diaspora (2012).](https://www.youtube.com/watch?v=ZCBB0QEmT5g)

[^hors-distribution]: So-called "out-of-distribution" data are data that are very distinct from all other data. They are often considered erroneous or even adversarial, so many learning algorithms seek to eliminate them.  
[**Paper.** Machine Learning with Adversaries: Byzantine Tolerant Gradient Descent. Peva Blanchard, El Mahdi El Mhamdi, Rachid Guerraoui & Julien Stainer. NIPS (2017).](https://proceedings.neurips.cc/paper/2017/hash/f4b9ec30ad9f68f89b29639786cb62ef-Abstract.html)  
[**Paper.** A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks. Kimin Lee, Kibok Lee, Honglak Lee & Jinwoo Shin. NeurIPS (2018).](https://proceedings.neurips.cc/paper/2018/file/abdeb6f575ac5c6676b747bca8d09cc2-Paper.pdf)  
Security-drivent algorithms are usually designed to ignore out-of-distribution data, which therefore leads them to ignore minorities. In fact, as discussed in the following article, there is a fundamental tension between inclusion and security. To resolve this tension, it is critical to better understand distributions (and model our well-founded priors), to better secure and authenticate data sources, or to be much more modest in our algorithm design.  
[**Paper.** Collaborative learning in the jungle. El-Mahdi El-Mhamdi, Sadegh Farhadkhani, Rachid Guerraoui, Arsany Guirguis, Lê Nguyên Hoang & Sébastien Rouault. NeurIPS (2021).](https://arxiv.org/abs/2008.00742)

> What do you mean?

> Issa's video data are perfectly normal. It is his spectrographic data that is reported as "very concerning". But I'm afraid that's because Issa is a statistically very different SmartToilet Deluxe user from other SmartToilet Deluxe users.

> He's Senegalese.

> Oh no... I think we have a big problem. Do you have the doctor's number? We need to call her right away.

### Nocebo effect

Marc dials Dr. Marta's number.

> Hello Dr. Marta, this is Marc. You are currently on speakerphone with Katia and me, President and Vice President of SmartPoop. We have an update on Issa's case.

> Hello Dr. Marta, this is Katia. I've analyzed Issa's case, and I'm pretty sure it's a false positive. In other words, SmartPoop made a mistake in reporting a problem with Issa's data.

> Hello Marc and Katia, replies Dr. Marta. Are you sure of what you are saying? Issa has some worrying symptoms, especially on the digestive level and in terms of fatigue.

> This is weird. The data I have doesn't seem to suggest symptoms of concern, says Katia.

> It may be a *nocebo* effect, says Marc.

> A *nocebo* effect? Yes, this could be it, indeed, exclaims Dr. Marta.

> A *nocebo* effect, asks Katia, what's that?

> When a patient thinks that something horrible is going to happen to him, they often develop the symptoms they fear, explains Marc. Digestive symptoms, for example, are quite likely. Issa probably trusts SmartPoop so much that when SmartPoop told him it was very concerned about his condition, his condition became very concerning[^nocebo].

[^nocebo]: [**Video.** This Video Will Hurt. CGP Grey (2013).](https://www.youtube.com/watch?v=O2hO4_UEe-4)

> But explain to me, asks Dr. Marta. Why was his case of false positive? Until now, whenever SmartPoop declared a case of "highly concerning" in our hospital, it always ended up in the intensive care unit, and then in death. That's why I panicked about Issa myself - which probably contributed to his *nocebo*.

> We just rolled out the SmartToilets and SmartToilets Deluxe, says Katia. I think that the SmartToilets make quite reliable diagnostics. But the Deluxe version has even more advanced sensors, which have not been used as much as the basic SmartToilets. And that's why it's not quite as reliable.

> I understand, thank you, says Dr. Marta. I'll let Issa know. Hopefully, it will help cure his *nocebo*. Can I ask you to manually correct his SmartPoop?

> It's... done, says Katia, after entering some commands on her computer.

> Thank you very much! Have a nice day, concludes Dr. Marta, before hanging up.

### 163 false positives

Katia hangs up twice, to verify that Dr. Marta is no longer connected. Katia then types several new commands, which display three new graphs. She turns to Marc.

> Well done Katia. Always there to rescue us, exclaims Marc.

> Marc, I don't think you realize yet how crappy of a situation we are in.

> I'm getting fed up with such phrasings. Isn't the problem solved?

> I'm going to do the updates this afternoon to avoid more false positive alerts. But the damage is already done. SmartPoop has issued 163 false positive alerts for SmartToilet Deluxe users.

> That's 163 phone calls to make. It's not the end of the world!

> Marc, this is not the heart of the matter.

> What is the problem?

> The problem is that the 163 false positives are all of African origin, and that's not a coincidence.

> What's going on?

> SmartPoop is... racist, says Katia with a serious tone.

> Racist? What are you talking about? It's an algorithm, not a human.

> What I mean is that it is dangerous for black Africans. And as a result, we're going to undergo a huge *shitstorm* in the next few weeks, for deploying a racist technology *before* we've tested it enough[^facial-recognition].

[^facial-recognition]: This was the case with facial recognition technologies, which were deployed in a hurry before external audits discovered that these technologies have an unacceptable error rate for minorities, which could sometimes prevent them from entering their own buildings, when such entry was allowed by such algorithms. These technologies were eventually banned by the US Congress, which led to a retraction of products developed by IBM, Amazon and Microsoft.  
[**Video.** Coded Bias. Netflix (2020).](https://www.netflix.com/title/81328723)  
A recent paper argues that similar action is urgently needed for language processing algorithms, whose poorly understood and under-addressed vulnerabilities have a high potential to lead to disaster.  
[**Paper.** Ever larger language models are ever more dangerous: A theoretical perspective. *forthcoming*.]( )

> Wait. Are you suspecting one of our developers of being a racist and making our algorithm do this?

> No. It's not that. Today, with machine learning, algorithms learn much more from data than from developers. So their performance depends on the quality and quantity of the data available[^manipulation-by-data]. Except that the data available through SmartToilet Deluxe is only the data from SmartToilet Deluxe users...

[^manipulation-by-data]: The example that shows this better than any other is probably the story of Tay and Xiaoice. Both of these conversational algorithms from Microsoft were built on the same principles. However, Tay was launched on Twitter, where it was derailed by troll data that encouraged it to express sexist and racist comments. Tay even went so far as to call for the genocide of certain populations. However, what's less known in Europe and North America, is that Xiaoice was launched 2 years ago on Chinese social medias (WeChat in particular). Xiaoice became adorable. So much so that Xiaoice is now used by 600 million Chinese people, with stories of men romantically seduced by Xiaoice. So, Tay has become horrible; Xiaoice has become adorable. Why is that? Well, because of the data that these algorithms were trained with.  
[**Journal.** Xiaoice Vs. Tay: Two A.I. Chatbots, Two Different Outcomes. SAMPi (2016).](https://sampi.co/chinese-chatbot-xiaoice-vs-tay/)

> But these users are almost exclusively white and Asian, Marc adds.

> Yes... This product is a luxury product. It is therefore bought only by rich people, who happen to be mostly white and Asian.

> I see. Because of the lack of data on black Africans, SmartPoop has become bad at diagnosing their excrement.

> It's worse than that, Marc. In medicine, when something is abnormal[^anormal]...

[^anormal]: The notions of "normal" and "abnormal" have long shaped medical discourse. For example, homosexuality has long been considered "abnormal", leading the American Psychological Association to refer to it as a "mental disorder". In 1975, the Association reversed this judgment, and no longer considers it a mental disorder.  
[**Web.** Sexual Orientation & Homosexuality. The American Psychological Association (2021).](https://www.apa.org/topics/lgbtq/orientation)

> It is considered a concern. Hence the alert...

> Guess how many SmartToilet Deluxe users are of African descent.

> No... 163 ? No... But why?

> The excrement of users of African origin obviously has different physiological characteristics.

> Ah yes... I know that they are more easily deficient in vitamin D, especially when they live in areas with little sun in winter[^vitamin-D]. There are certainly other major distinctions, and some of them can definitely be seen via the SmartToilet Deluxe. Hence SmartPoop's concern for the health of these 163 users of African descent.

[^vitamin-D]: [**Paper**. Vitamin D and African Americans. Susan Harris. The Journal of Nutrition (2006).](https://pubmed.ncbi.nlm.nih.gov/16549493/)

> Marc, it's not just about being concerned. We've basically just classified all SmartToilet Deluxe users of African descent as "sick". We've automated racism!

> But we didn't do it intentionally[^side-effect].

[^side-effect]: Many of the ethical problems of algorithms, such as the amplification of hate speech or misinformation, have arguably more to do with the unwanted (and therefore unintentional) side effects of the algorithms. Therefore, to make these algorithms ethical, it is not enough to want them to be "neutral", or even to want them to be "reasonable"; it is critical to actively seek to anticipate their difficult-to-predict side effects, and to invest massively in the study of these side effects.  
[**Book.**  Le fabuleux chantier : Rendre l'intelligence artificielle robustement bénéfique. Lê Nguyên Hoang et El Mahdi El Mhamdi. EDP Sciences (2019). *English translation pending*.](https://laboutique.edpsciences.fr/produit/1107/9782759824304/Le%20fabuleux%20chantier)

> Go explain this to the media! I fear the worst. We'll get sensationalist headlines like "SmartPoop is racist", and we'll probably risk a lawsuit. We risk losing our investors! And if we don't get more investors and a lawsuit on our ass, we might go bankrupt. And all this just a few days before SmartPoopCon... We have to keep this story quiet.

After a silence, Marc adds, "I think it's a waste of time. The 163 victims have probably all suffered from the *nocebo* effect, for which we are responsible."

> What do you mean "for which we are responsible"? All we've done is issue alerts. SmartPoop is only an aid to decision-making.

> The problem is that our users trust SmartPoop so much that our decision aids have become decisions for the users. You saw it with Issa's case. When we told him to go to the emergency room, do you think he took that as a decision aid? No, he thought, oh boy, I have to go to the emergency room[^help-decision]. And worse than that, he developed symptoms!

[^help-decision]: When a decision support algorithm becomes powerful, it seems important to see it as more than just a decision "aid". Like Google Map, such algorithms can end up being listened to almost blindly by their users, so that the decision aid becomes essentially the decision itself.

> OK. But it's not like we tortured Issa!

> I've seen some terrifying *nocebo* experiments. In one of them, a patient just sits there. Nothing is done to her. But she is put in conditions that are conducive to *nocebo*. On a scale from 0 to 10, the patient reported a pain of 9.5. A pain of 9.5 out of 10! Like, it was probably for her comparable to the pain of childbirth[^experience-nocebo]!

[^experience-nocebo]: Marc is referring to this video here:  
[**Video.** Touch - Mind Field (Ep 6). VSauce (2017).](https://www.youtube.com/watch?v=OUdXMoY6fLY)

> Wait, are you saying that, via SmartPoop, black Africans were targeted for torture? That's bullshit!

> Clearly, we didn't do it intentionally. But yes, if you take a step back, I think you can say that's what we did...

> Well... Anyway, we need to get ahead of this thing before it blows up. I'm going to reorganize SmartPoopCon, to talk about the problem we have, and what we plan to do to prevent our algorithms from being racist and causing such suffering.

### Inclusion and diversity

A few days later, at SmartPoopCon 2024, SmartPoop's major annual conference, Katia took the stage to announce her company's new diversity and inclusion measures.

> In our industry, we tend to constantly want to move forward, introducing new projects for the future. We are expected to *innovate*. But that's not SmartPoop's mission. SmartPoop's mission is to provide unparalleled health care to all our users. SmartPoop's mission is to care for the health and well-being of *every* human on earth. And today, I would like to publicly reaffirm SmartPoop's commitment to this goal.
>
> But to do that, to really take care of all the people on earth, rather than constantly searching for the next idea, it's also critical to monitor our technologies and make sure they're working properly. At SmartPoop, we routinely do just that. Unfortunately, recently we realized that we have a systemic bias in the way we test our products. Because our engineering teams are primarily white men, they often fail to think about minority concerns. To close this gap, we believe we need to introduce much more social diversity into our teams. That's why we're actively committed to combating our systemic biases by promoting the recruitment of populations currently underrepresented among our employees[^diversity].
>
> So I wish I could tell you that we made this decision because we've always prioritized ethics. But to be honest with you, I have to admit that this decision comes first and foremost from the realization, unfortunately too late, that one of our technologies was not up to our ethical standards. SmartPoop, applied to the SmartToilet Deluxe, suffered from what is called a *distributional shift*, i.e. a discrepancy between its training data and practical application cases, which unfortunately led to diagnostic errors for certain populations[^distributional-shift]. To all our users who have suffered from these errors, but also to all these populations, we sincerely apologize.
>
> Unfortunately, without sufficient data from certain populations, it is in fact mathematically impossible to guarantee the same quality of service to these populations as we offer to other populations. At SmartPoop, we believe that technologies should be inclusive. Given the impact of these technologies on modern society, we believe that it would be immoral to offer these technologies only to certain populations, and even more so to already privileged populations. For this reason, we have decided to drastically subsidize the SmartToilets Deluxe to those populations where we lack the data to establish reliable and relevant medical alerts. The budget for this operation is estimated at $100 million. This is a huge amount of money for us; but it is a small price to pay for social equality in our societies.
>
> The subject of the impact of technology on social inequality is complex. Many companies prefer to avoid it. However, unlike some of our competitors[^whitelist-facebook], we don't want to sweep these issues under the rug. It is high time that the technology industry actively seeks to understand the harmful consequences of their technologies[^human-trafficking-facebook]. We are thus committed to investigating any potential concern, and to transparently revealing to you the problems we encounter[^gebru-firing]. Be aware, however, that in doing so, we will be revealing problems that are often pervasive throughout the technology industry. If we are victims of some technological flaw, other tech companies are almost surely victims too. When you do our trial, consider doing the trial of the entire technology industry, and remember that the companies that will reveal their problems the least are probably the ones that have the most problems[^transparency-backfire].
>
> Overall, I'd like you to think about asking yourself the most important question in the tech industry: is my trust in this or that company's product justified[^calibration]?

[^diversity]: Several studies point to the importance of diversity for a group's creativity. However, there seem to be confusing and contradictory results regarding the impact of diversity on group effectiveness. This is probably not surprising, considering that this impact most likely depends on many other factors, such as the task assigned to the group, the emotional sensitivity of the group members and the organization of the group.  
[**Paper.** Collective Intelligence and Group Performance. Anita Williams Woolley, Ishani Aggarwal & Thomas W. Malone. Current Directions in Psychological Science (2015).](https://journals.sagepub.com/doi/full/10.1177/0963721415599543)  
[**Paper.** Evidence for a Collective Intelligence Factor in the Performance of Human Groups. Anita Wooley, Christopher Chabris, Alex Pentland, Nada Hashmi & Thomas Malone. Science (2010).](https://www.science.org/doi/full/10.1126/science.1193147)

[^distributional-shift]: [**Paper.** Preventing Failures Due to Dataset Shift: Learning Predictive Models That Transport. Adarsh Subbaswamy, Peter Schulam & Suchi Saria. AISTATS (2019).](https://proceedings.mlr.press/v89/subbaswamy19a.html)

[^whitelist-facebook]: The *facebook files* reveal that, contrary to what Mark Zuckerberg has repeatedly stated publicly, Facebook maintains a secret *whitelist* of personalities exempt from Facebook's content moderation policy, including leaders of authoritarian countries. Yet, this boils down to empowering those who probably already have too much power. For example, because soccer player Neymar is a global star, and his Facebook presence attracts a lot of views, Facebook allowed him to post a *revenge porn* video, which exposes images of a naked woman without her consent. Such a post is prohibited by the [Facebook Community Standards](https://transparency.fb.com/policies/community-standards/), and should have led to Neymar being banned from Facebook.  
[**Podcast.** The Facebook Files, Part 1: The Whitelist. The Journal (2021).](https://www.wsj.com/podcasts/the-journal/the-facebook-files-part-1-the-whitelist/aa216713-15af-474e-9fd4-5070ccaa774c?mod=article_inline)

[^human-trafficking-facebook]: The *facebook files* also reveal that Facebook management repeatedly discouraged the investigation of potential problems on the platform. More generally, by insisting that any company can be punished if it *knowingly* facilitates illegal acts, the law misguidedly encourages companies not to investigate any such problems, because once it can be shown that companies were aware of these problems, they then have a legal duty to invest heavily in solving these problems, which is very costly for them.  
[**Podcast.** The Facebook Files, Part 3: 'This Shouldn't Happen on Facebook'. The Journal (2021).](https://www.wsj.com/podcasts/the-journal/the-facebook-files-part-3-this-shouldnt-happen-on-facebook/0ec75bcc-5290-4ca5-8b7c-84bdce7eb11f)

[^gebru-firing]: Very clearly, Google does not have this standard at all. As a reminder, the two co-directors of Google's ethics team were fired in turn, following the publication of a scientific paper discussing the ethical, environmental and social risks of deploying advanced language processing technologies.  
[**Video.** Google fired its ethics. This is terrifying. Science4All (2021).](https://www.youtube.com/watch?v=fe9u6YQTsWY)

[^transparency-backfire]: Unfortunately, today, companies that communicate more about the problems they face are often criticized more than those that hide their problem. Typically, Twitter's more transparent policy seems to have led to more criticism than Facebook's very opaque policy. Or to take another more concrete example, in 2014 Facebook publicly shared the (fascinating) result of its analysis of the impact of a very slight reduction in the publication in News Feeds of posts with negative emotions on what users exposed to those posts would start writing in turn.  
[**Podcast.** Can Algorithms Choose our Emotions? Robustly Beneficial (2020).](https://www.youtube.com/watch?v=gQHvTow91FY)  
[**Paper.** Experimental evidence of massive-scale emotional contagion through social networks. Adam Kramer, Jamie Guillory & Jeffrey Hancock. PNAS (2014).](https://www.pnas.org/content/111/24/8788)  
This study, however, led to an outcry about the ethics of such studies.  
[**Paper.** Facebook's emotional contagion study and the ethical problem of co-opted identity in mediated environments where users lack control. Evan Selinger, Woodrow Hartzog. Research Ethics (2015).](https://journals.sagepub.com/doi/full/10.1177/1747016115579531)  
An unfortunate consequence of this outcry, however, is that Facebook has stopped publishing such studies, even though Facebook has certainly not stopped conducting these studies, as well as studies much less relevant for ethics (such as A/B testing of the most addictive content). As a result, from the outside, it is very difficult to understand the impact of Facebook. In fact, the *facebook files* show that this has mostly allowed Facebook to hide the extent of its harmful impacts, such as on the mental health of teenage girls who use Instagram.  
[**Podcast.** The Facebook Files, Part 2: 'We Make Body Image Issues Worse'. The Journal (2021).](https://www.wsj.com/podcasts/the-journal/the-facebook-files-part-2-we-make-body-image-issues-worse/c2c4d7ba-f261-4343-8d18-d4de177cf973)  
More generally, there seems to be a tension here between *idealism* and *consequentialism*. While consequentialism seeks to improve the state of the world as much as possible, idealism sets itself an ideal and refuses any action that seems contradictory to that ideal, even if that ideal is pragmatically unattainable in the near future.  
[**Podcast.** Radically Normal: How Gay Rights Activists Changed The Minds Of Their Opponents. Hidden Brain (2019).](https://www.npr.org/2019/04/03/709567750/radically-normal-how-gay-rights-activists-changed-the-minds-of-their-opponents)

[^calibration]: The fundamental issue Katia raises here is that of (trust) *calibration*. For example, if a person is calibrated in their predictions, on the set of times they say an event will happen with 80% probability, that person must have seen right 8 times out of 10. In the age of new technologies, unfortunately, the confidence assigned to some products is unjustifiably high, while the confidence assigned to other products is unjustifiably low.  
[**Paper.** Practical Guidance for Evaluating Calibrated Trust. Patricia McDermott & Ronna ten Brink. Human Factors and Ergonomics (2019).](https://journals.sagepub.com/doi/abs/10.1177/1071181319631379)

## To go further

Don't stop there!
Check [the sequel of the novel](4-leak.md) or the [outline](README.md).  
If you enjoyed it, please consider sharing and promoting this science fiction novel to others!

