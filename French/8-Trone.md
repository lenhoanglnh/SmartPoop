# 8. Sur le trône

Devant un stade plein, et avec les caméras du monde entier braquées sur elle, Katia entre sur scène sous les ovations du public, comme une star de rock. Cette année, SmartPoop a mis des gros moyens pour un SmartPoopCon 2030 hors norme.

> Bonsoir à tous et merci d'être venus aussi nombreux ! Est-ce que vous allez bien ? Est-ce que vous êtes prêts à marquer l'histoire ?

### Les statistiques de Poo

À ces mots, le public s'enflamme comme si son équipe de football venait de marquer un but.

> J'aimerais commencer cette conférence avec un chiffre : 100 000. C'est l'objectif qu'on s'était fixé il y a deux ans, pour le lancement de Poo. On espérait diviser par 10 le nombre de suicides dans le monde en cinq ans, le ramener de son chiffre historique de 1 million suite au ROVID-19 en 2022[^suicides], à seulement 100 000. Un objectif considéré irréaliste par tant de gens, y compris le journal La Terre. Où en sommes-nous aujourd'hui, en 2030 ?

[^suicides]: En 2020, on estimait qu'il y avait autour de 800 000 suicides par an à travers le monde.  
[**Web.**  Suicide. Our World in Data (2020).](https://ourworldindata.org/suicide)  
Parmi les pays les plus affectés par ces suicides, on trouve aussi bien des pays peu développés, moyennement développés et très développés, comme le Suriname, la Russie et la Corée du Sud. Essentiellement tous les pays développés ont un taux de suicides malheureusement très élevé, avec souvent plus d'un suicide pour 10 000 personnes.  
[**Web.**  Suicide death rates. Our World in Data (2019).](https://ourworldindata.org/grapher/suicide-mortality-rate)

Katia marque un silence.

> Je vous propose un décompte pour le découvrir.

La jingle musical reprend le relai du discours de Katia, et conclut avec un décompte, repris en choeur par un public bouillant. Trois. Deux. Un. À zéro, sur l'écran géant derrière Katia, le chiffre de 97 643 est affiché à l'écran !

> On l'a fait !!

Le public célèbre se chiffre comme s'il supportait une équipe de football qui venait de marquer le but de la victoire dans la dernière minute. Les applaudissements du public se mettent alors en rythme, et s'éternisent pendant toute une minute.

> Poo, notre psychiatre algorithmique, accompagne désormais des milliards d'entre nous dans nos déboires mentaux. Et ce ne sont pas que les suicides qu'il est parvenu à combattre. Laissez-moi vous présenter d'autres courbes, qui ont été validées par différents auditeurs externes, grâce à la coordination de l'OMESA. Mesdames et messieurs, voici le pourcentage de communications joyeuses avec Poo au cours du temps.

Une courbe apparaît alors à l'écran, tracée doucement de gauche à droite. Cette courbe démarre à 37%, et ne cesse d'augmenter au cours du temps, jusqu'à atteindre le chiffre de 67%, sous les hourras d'un public déchaîné.

> 67% !! Incroyable ! Poo a rendu toute l'humanité joyeuse[^emotional-contagion] !

[^emotional-contagion]: En 2014, une publication de Facebook et de co-auteurs académiques a montré qu'une réduction très légère de la publication, dans les fils d'actualités, de posts avec des émotions négatives, conduit les utilisateurs exposés à ces posts à écrire des messages plus joyeux.  
[**Vidéo.**  L'IA nous gouverne déjà. Science4All (2018).](https://www.youtube.com/watch?v=Z2G4q-E_oHA&list=PLtzmb84AoqRTl0m1b82gVLcGU38miqdrC&index=29)  
[**Podcast.**  Can Algorithms Choose our Emotions? Robustly Beneficial (2020).](https://www.youtube.com/watch?v=gQHvTow91FY)  
[**Science.**  Experimental evidence of massive-scale emotional contagion through social networks. Adam Kramer, Jamie Guillory & Jeffrey Hancock. PNAS (2014).](https://www.pnas.org/content/111/24/8788)  
À l'inverse, les *facebook files* révèlent que la recherche interne de Facebook, gardée secrète, montre que les algorithmes qui maximisent l'engagement des utilisateurs, et qui ont été déployés en 2018 par Facebook, ont conduit à beaucoup plus de colère et d'insultes.  
[**Podcast.**  The Facebook Files, Part 4: The Outrage Algorithm. The Journal (2021).](https://www.wsj.com/podcasts/the-journal/the-facebook-files-part-4-the-outrage-algorithm/e619fbb7-43b0-485b-877f-18a98ffa773f)

Le public exprime d'ailleurs cette joie, à la vue de cette courbe et de ce chiffre.

> Quand vous parlez à Poo, vous pouvez parler de vous, de votre bien-être et de vos problèmes, ce que je vais appeler le discours égocentrique. Ou vous pouvez parler des autres, de la joie qu'ils vous procurent, des difficultés qu'ils traversent et des choses que vous pouvez faire pour les aider. Je vais appeler cela le discours hétérocentrique[^heterocentrique]. Avant le lancement de Poo, 57% des discussions Poo étaient égocentriques plutôt qu'hétérocentriques. D'après vous, comment a évolué ce chiffre ? Vers le haut ?

[^heterocentrique]: À ne pas confondre avec *l'hétérocentrisme* qui consiste à considérer que l'hétérosexualité est la norme absolue, et que tout ce qui dévie de l'hétérosexualité devrait être punie.

Le public crie alors en choeur « non ».

> Vers le bas ?

Le public crie en choeur « oui ».

> Découvrons cela !

À l'écran, la même animation que précédemment montre une courbe qui descend, jusqu'à atteindre 44%, sous les ovations du public.

> Oui ! 44%. Désormais, la plupart des discussions avec Poo sont des discussions centrées sur l'environnement social plutôt que sur soi-même. Et alors, il faudrait se méfier de ce chiffre a priori. Initialement, la plupart des discussions hétérocentriques consistaient à se plaindre des autres, à moquer certains groupes, voire à attaquer certains groupes sociaux[^appel-a-la-meute], plutôt qu'à célébrer les autres, à se réjouir de leurs succès et à réfléchir à comment leur venir en aide. Avant le lancement de Poo, 86% des discussions hétérocentriques étaient critiques, et pas bienveillantes. Comment a évolué cette statistique ?

[^appel-a-la-meute]: [**Vidéo.**  La morale des hooligans (LA NÔTRE !!). Science4All (2017).](https://www.youtube.com/watch?v=ki26tUbxpnU&list=PLtzmb84AoqRSmv5o-eFNb3i9z64IuOjdX&index=27)  
[L'appel à la meute #DébattonsMieux. Science4All (2019).](https://www.youtube.com/watch?v=P0YB40z7RJ0)

Le public crie alors de façon désorganisée « vers le bas ». Puis à force de se répéter, les cris se synchronisent, avant de répéter « vers le bas », « vers le bas », « vers le bas ».

> Voyons cela..

L'écran géant montre l'évolution de cette courbe, qui en effet plonge vers le bas, jusqu'à atteindre 47%, sous les applaudissements du public.

> Incroyable !! La société est devenue incroyablement plus bienveillante et altruiste en l'espace de deux ans seulement ! D'ailleurs, l'expression « les plus démunis » est utilisée aujourd'hui 3 fois plus souvent qu'il y a deux ans, tandis que l'expression « générations futures » est utilisée 4 fois plus souvent. Et d'après de nombreux psychiatres, cette progression est très probablement directement liée à Poo, et à l'amélioration de la santé mentale de nos utilisateurs. Quand on se porte mieux soi-même, on est tout de suite beaucoup plus prompt à souhaiter le bonheur des autres et à leur venir en aide[^altruism-happiness] !

[^altruism-happiness]: De nombreuses études semblent montrer une association importante entre l'altruisme et le bonheur. De façon intrigante, il semble en particulier qu'être altruiste augmente le bonheur, notamment par opposition à dépenser notre argent pour nous-même.  
[**Science.**  Altruism, happiness, and health: it’s good to be good. Stephen Post. International Journal of Behavioral Medicine (2005).](https://link.springer.com/article/10.1207/s15327558ijbm1202_4)    
[**Vidéo.**  Helping others makes us happier -- but it matters how we do it | Elizabeth Dunn. TED (2019).](https://www.youtube.com/watch?v=lUKhMUZnLuw)  
[**Livre.**  Happy Money: The Science of Smarter Spending. Elizabeth Dunn and Michael Norton. Simon & Schuster (2013).](https://www.simonandschuster.com/books/Happy-Money/Elizabeth-Dunn/9781451665079)

### Les héros derrière Poo

> Mais donc, qu'en dites-vous ? Poo, succès ou échec ?

Le public crie « succès » de manière désordonnée, mais néanmoins distinguable.

> Eh bien, mesdames et messieurs, je pense que Poo n'est pas un échec.

Katia marque une pause, alors que le public applaudit.

> Et ça, c'est grâce au travail formidable de tant de passionnés, tant de gens qui ont donné tellement de leur temps et de leur argent pour améliorer et sécuriser Poo. J'ai une pensée énorme bien sûr pour tous mes collègues à SmartPoop, et leur dévotion incroyable. Mais ils ne sont pas les seuls responsables de SmartPoop. Poo a été conçu grâce à une collaboration étroite et quotidienne avec des milliers de psychiatres et de psychologues à travers le monde, et grâce aux données de discussions de millions de psychiatres et patients volontaires. Rien n'aurait été possible sans eux[^donnees-experts].

[^donnees-experts]: Il est bon de rappeler que les algorithmes de machine learning *apprennent des données*. Ils ne pourront ainsi accomplir des tâches difficiles, comme accompagner thérapeutiquement la santé mentale de leurs utilisateurs, que si ces algorithmes disposent d'une énorme quantité de données fiables et sécurisées qui leur permettent de comprendre comment accomplir ces tâches.  
[**Vidéo.**  Les données manipulent les algorithmes. Science4All (2021).](https://www.youtube.com/watch?v=vYb3rB0jU70&list=PLtzmb84AoqRRFcoGQ5p7kqEVQ7deXfYuH&index=3)

Katia profite des applaudissements du public pour marquer une autre pause.

> Mais ce n'est pas tout. Poo, c'est le produit de toute la civilisation humaine. En particulier, rien n'aurait été possible sans les accords entre les grandes puissances mondiales, qui ont permis la création de l'OMESA, et la coordination planétaire de la recherche sur l'éthique et la sécurité des algorithmes. Je remercie ainsi également tous les scientifiques à travers le monde qui ont abandonné leurs quêtes de performance, ou parfois leurs quêtes de l'élégance mathématique, pour relever le défi de l'éthique et de la sécurité[^quete-performance]. Mais plus que cela, l'OMESA a souvent servi de contre-pouvoir face à la quête du pouvoir militaire et économique des gouvernements et des entreprises. Sans eux, les algorithmes les plus influents d'aujourd'hui seraient des malwares de cyber-guerre et des algorithmes optimisés pour retenir l'attention des utilisateurs en promouvant du putaclic sensationnaliste. Personnellement, je pense que chaque membre et chaque bénévole de l'OMESA a sauvé l'humanité.

[^quete-performance]: En 2021, la recherche académique (et plus encore l'industrie) demeure encore largement obsédée par la quête de performances ou de résultats « impressionnants », aussi bien en machine learning qu'en informatique de manière générale, en s'appuyant sur des métriques comme *l'accuracy* (la performance prédictive sur un jeu de données « classique »), le temps de calcul, le *throughput* (la quantité d'information transmise) ou la latence. Alors que les algorithmes ont déjà des effets secondaires monumentaux à l'échelle planétaire, ces recherches semblent aggraver la course à la performance, et donc le déploiement précipité de technologies mal testées et rarement auditées.  
À titre d'exemple, voici un commentaire d'un *revieweur* anonyme de NeurIPS 2019, suite à un article soumis par Lê Nguyên Hoang et ses co-auteurs sur un algorithme pour débiaiser les biais racistes des algorithmes : « Malheureusement, je ne pense pas que le problème introduit par les auteurs est un problème qui a de la valeur pour la communauté académique ou pour les praticiens du ML. Dès lors, je ne peux pas recommander la publication de l'article. »  
[**Science.**  Removing Algorithmic Discrimination (With Minimal Individual Error). vidual Error) El Mahdi El Mhamdi, Rachid Guerraoui, Lê Nguyên Hoang & Alexandre Maurer (2018).](https://arxiv.org/abs/1806.02510) <!-- « Unfortunately, I don't think the problem the authors introduce is one that has value to the academic community or to ML practitioners. Given this, I can't recommend the paper for publication. »   -->
Ceci étant dit, il y a récemment eu de nombreux progrès, comme la création de la conférence Fairness, Accountability and Transparency (FAccT), l'introduction de *guidelines éthiques* dans ces conférences, ou encore l'ajout obligatoire d'une discussion des auteurs dans leurs articles des impacts sociétaux de leur recherche.  
[**Vidéo.**  L'éthique des algorithmes en sérieux danger. Science4All (2020).](https://www.youtube.com/watch?v=Ddr-BZ9W180)

À nouveau, Katia marque une pause pendant les applaudissements du public.

> Enfin, et surtout, je tiens à remercier chacun des acteurs et signataires de la lettre ouverte, ainsi qu'à chacun des journalistes et des influenceurs qui ont couvert cette affaire, grâce à qui SmartPoop a pu se remettre dans le droit chemin. Ces femmes et ces hommes ont risqué leur vie, leur bien-être et leur sécurité individuels, pour venir en aide au plus grand nombre[^whistleblower]. Sans eux, qui sait ce que SmartPoop serait devenu ? Qui sait ce que je serais devenue ?

[^whistleblower]: Malheureusement, les lanceurs d'alerte souffrent souvent de davantage de troubles de santé mental suite à leurs actes courageux. Vu le rôle critique qui joue pour révéler des scandales dans des entreprises et des organisations dangereusement opaques, il semble urgent de beaucoup mieux les accompagner.  
[**Science.**  Mental Health Problems Among Whistleblowers: A Comparative Study. Peter van der Velden, Mauro Pecoraro, Mijke Houwerzijl & Erik van der Meulen. Psychological Reports (2018).](https://journals.sagepub.com/doi/10.1177/0033294118757681)

Seule sur scène, Katia lâche une larme.

> Merci à ces héros, dit-elle en pleurs.

Le public applaudit ce moment très émouvant.

### Le défi de l'éthique de Poo

Katia a encore besoin de plusieurs secondes pour reprendre ses émotions. Finalement, elle se reprend.

> Néanmoins, je refuse de dire que Poo est un succès. Ensemble, nous avons créé un produit incroyable. Mais il reste infiniment améliorable, notamment sur le plan de son éthique, de sa sécurité et de sa gouvernance. Comment contrôle-t-on Poo ? Comment empêche-t-on Poo de dire des mots blessants, de révéler des secrets, de répéter des discours de haine et de diffuser de la mésinformation[^language-model] ? Comment l'amène-t-on à être bienveillant avec ses interlocuteurs, à dire les mots justes pour les rendre plus épanouis et à promouvoir autant que possible de l'information fiable et non trompeuse[^non-trompeur] ? Comment l'amène-t-on à mieux réfléchir, et à vouloir investiguer ses incertitudes plutôt que de se contenter de ses intuitions[^scout] ? Mais surtout, comment peut-on décider collectivement de ce que Poo doit dire ? Comment déterminer ce qui est désirable à dire, et ce qui ne devrait jamais être dit[^ethics-of-influence] ?

[^language-model]: Ces problèmes ne sont absolument pas résolus pour les algorithmes conversationnels modernes, qui sont très vulnérables à des attaques d'espionnage ou par empoisonnement des données. Et pourtant, ces algorithmes sont déjà déployés à très grande échelle, via les claviers intelligents, via les assistants personnels (Siri, Alexa, OK Google) et via les moteurs de recherche (Google, YouTube).  
[**Science.**  On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?  Emily Bender, Timnit Gebru, Angelina McMillan-Major & Shmargaret Shmitchell. FAccT (2021).](https://dl.acm.org/doi/10.1145/3442188.3445922)  
[**Science.**  The Radicalization Risks of GPT-3 and Advanced Neural Language Models. Kris McGuffie, Alex Newhouse (2020).](https://arxiv.org/abs/2009.06807)  
[**Science.**  Extracting Training Data from Large Language Models. Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Ulfar Erlingsson, Alina Oprea & Colin Raffel. USENIX (2021)](https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting)

[^non-trompeur]: [**Vidéo.**  Qu’est ce qu’un message d’utilité publique ? Science4All (2021).](https://www.youtube.com/watch?v=LZGhBmDVi5A&list=PLtzmb84AoqRRFcoGQ5p7kqEVQ7deXfYuH&index=5)

[^scout]: Julia Galef parle du *scout mindset* (ou *mode explorateur*), par opposition au *soldier mindset* (*mode soldat*). Selon elle, il s'agit de l'aspect le plus déterminant pour analyser de l'information plus correctement.  
[**Vidéo.**  Comment j'essaye d'améliorer mon jugement (grâce à Julia Galef et à FLUS). Science Étonnante (2021).](https://www.youtube.com/watch?v=Sm_FgccC9dk)
[**Vidéo.**  Le mode explorateur. Science4All (2021).](https://www.youtube.com/watch?v=EZfNX4U63hc)  
[**Livre.**  The Scout Mindset: Why Some People See Things Clearly and Others Don't. Julia Galef. Penguin (2021).](https://www.penguinrandomhouse.com/books/555240/the-scout-mindset-by-julia-galef/)

[^ethics-of-influence]: Chaque mot choisi ou chaque recommandation faite par un algorithme peut être vu comme un *nudge*. De nombreuses études montrent que l'acceptabilité et l'efficacité des *nudges* dépendent fortement du *nudge* considéré ; avec plus de données à ce sujet, il pourrait être ainsi possible de mettre en oeuvre les nudges particulièrement acceptés socialement et efficaces.  
[**Livre.**  The Ethics of Influence: Government in the Age of Behavioral Science. Cass Sunstein. Cambridge University Press (2016).](https://www.cambridge.org/core/books/ethics-of-influence/E29EDE19EBCB53F6D8691730668115F7)

Katia marque une pause, devant un public tout ouï.

> Et ça, ça m'amène à la fameuse rumeur dont vous avez sans doute entendu parler. Comme quoi, on aurait un plan pour résoudre le problème de l'éthique de l'information…

Katia marque alors un silence, avant de rajouter sur un ton sarcastique.

> Genre, « SmartPoop, cette application de merde, va résoudre l'éthique ».

Le public rit en cœur.

> Vous savez, il ne faut pas croire tout ce qu'on vous dit.

Katia marque un autre silence.

> Mais dans ce cas, oui c'est vrai. Ou du moins, on compte y contribuer.

Le public rit.

> Et, je le sais bien, car c'est moi qui ai fait fuiter la rumeur.

Le public, conquis, rit à nouveau, même si beaucoup commencent à avoir un visage confus.

> Ceci dit, chez SmartPoop, l'éthique de l'information nous tient clairement à cœur. Nous voulons déterminer quelles informations devraient être collectées par qui et dans quelles conditions, comment elles devraient être stockées, à qui ces informations devraient être accessibles, quels traitements de cette information devraient être effectués, comment ces traitements de l'information devraient être audités et sécurisés, où stocker les résultats de ces calculs, qui peut avoir accès à ces résultats, et qui sera notifié de l'existence de ces résultats[^information-serres].

[^information-serres]: [**Vidéo.**  Michel Serres - Les nouvelles technologies : révolution culturelle et cognitive. I Moved to Diaspora (2012).](https://www.youtube.com/watch?v=ZCBB0QEmT5g)

Après un autre silence, Katia reprend son discours.

> Et là, je sens qu'il y en a pas mal parmi vous qui se disent : « mais pour qui elle se prend, Katia ? »

Le public rit à nouveau.

> Bien entendu, beaucoup de ces opérations devraient être largement configurables par les utilisateurs. Ceci étant dit, la plupart des utilisateurs ne voudront pas gérer toutes les configurations de tous leurs systèmes d'information, et vérifier, par exemple, que ces configurations respectent le règlement pour la protection des données personnelles, ou empêchent la diffusion massive de discours de haine. Non, la plupart des utilisateurs sont comme moi : ce sont des fainéants.

Le rire du public permet alors à Katia de reprendre son souffle.

> Mais surtout, sur Internet, beaucoup d'utilisateurs veulent nuire à d'autres utilisateurs ; ou au moins les influencer d'une certaine manière. Pensez à toutes les campagnes de désinformation qui sévissent sur les réseaux sociaux[^desinformation-2]. Or, même l'un des plus grands défenseurs du libéralisme, le philosophe John Stuart Mill, pense que la liberté des uns doit s'arrêter là où elle nuit aux autres. Tel est le principe de l'absence de tort.

[^desinformation-2]: [**Vidéo.**  Les réseaux sociaux sont dangereux. Très dangereux. Science4All (2021).](https://www.youtube.com/watch?v=utWMGi8HTjY&list=PLtzmb84AoqRRFcoGQ5p7kqEVQ7deXfYuH&index=1)

Katia marque à nouveau une pause, et regarde son public, en déplaçant son regard de gauche à droite.

> L'un des grands défis de l'éthique de l'information, c'est l'implémentation du principe de l'absence de tort. Car pour autant que je sache, ce principe est quasi-consensuel en philosophie morale[^absence-tort] — et c'est un sacré exploit d'être consensuel en philosophie morale.

[^absence-tort]: [**Vidéo.**  Ce principe sur lequel tout le monde s'entend. Monsieur Phi (2021).](https://www.youtube.com/watch?v=JY3SAzlgBYY)

Katia marque un nouveau silence.

> Bon ça, c'est en principe. En pratique, c'est difficile de se mettre d'accord sur ce qui constitue un tort. Est-ce qu'un commentaire agressif cause un tort ? Est-ce qu'un petit mensonge cause un tort ? Est-ce qu'une blague au dépens d'une communauté cause un tort ? Malheureusement, en pratique, on ne sera pas d'accord. Nous avons des préférences éthiques difficilement réconciliables, voire parfois clairement irréconciliables. Que faire alors[^scrutins-sml] ?

[^scrutins-sml]: [**Vidéo.**  [Conférence SML] Les mathématiques de la démocratie - Lê Nguyên Hoang. Maison des mathématiques et de l'informatique (2018).](https://www.youtube.com/watch?v=CYqLfWFdFoc)

Katia semble vraiment poser cette question à son public, comme si elle attendait une réponse. Le public a l'air pensif, et attend impatiemment une réponse de Katia.

### Qui décidera de l'éthique Poo ?

Katia relance avec une autre question.

> Est-ce que SmartPoop devrait trancher ?

Le public reste silencieux. Clairement, il s'agit d'un groupe de fans de SmartPoop. Mais même eux ne semblent pas emballés à cette idée.

> Si vous voulez mon avis, la réponse est clairement non. On l'a vu il y a deux ans. Une structure comme SmartPoop peut perdre son éthique et sa voie. Et même si nous avons fait énormément de progrès dans notre gouvernance pour éviter que ceci ne se reproduise, je ne pense pas que SmartPoop soit suffisamment robustement bénéfique pour une telle tâche.

Katia marque une pause, comme si elle invitait sérieusement le public à y réfléchir.

> Mais donc, qui ? Qui devrait déterminer l'éthique de l'information et du traitement de l'information ?

Encore une fois, cette question est posée comme si Katia n'en avait aucune réponse, et comme si elle attendait du public une réponse. Après de longues secondes, Katia offre sa réponse.

> Eh bien, je propose que ce soit vous. Je propose que ce soit nous tous. Je propose que, ensemble, toute l'humanité décide collectivement de l'éthique de l'information.

Le public applaudit.

> Mais... Comment peut-on amener des milliards d'humains à décider collectivement de quelque chose d'aussi complexe que l'éthique de l'information ?

Le public est maintenant circonspect.

> Réfléchissez-y. Comment fait-on aujourd'hui pour prendre des décisions collectives ?

Katia marque à nouveau une pause, jusqu'à ce qu'elle entende quelqu'un dans le public crier « le vote ».

> Le vote, oui ! Dans beaucoup de pays à travers le monde, quand une décision collective doit être prise, on essaie souvent de se ramener à une question avec une réponse oui ou non, et on demande au peuple de voter pour oui, ou pour non ? C'est ainsi que l'on tranche des désaccords irréconciliables.

Katia s'arrête quelques secondes.

> Mais le problème du vote, en tout cas tel qu'il est pratiqué aujourd'hui, c'est qu'il ne permet à chaque citoyen d'envoyer que quelques bits d'information par vote seulement. La COP 30, pour ou contre ? La vaccination obligatoire, pour ou contre ? La régulation des algorithmes, pour ou contre ? Lequel des 15 candidats suivants devrait être élu ? Il n'y a pas 36 000 réponses possibles à ces questions. Or, pour résoudre l'éthique des algorithmes, il va falloir fournir des réponses complexes. Il y a même des milliards de milliards de discours qu'un utilisateur de SmartPoop peut produire. Parmi les milliards de réponses imaginables, laquelle Poo devra-t-elle adopter ?

Katia reprend son souffle, avant la suite de son discours.

> Et si on concevait désormais des votes où la voix de chacun n'était pas réduite à une réponse binaire[^mediane-geometrique], donnée uniquement une fois par an ? Et si on permettait à chacun de partager toute la complexité de son jugement éthique ? Et si on parvenait à tenir compte de toute cette complexité pour décider collaborativement de l'éthique de l'information[^licchavi] ?

[^mediane-geometrique]: L'une des solutions pour voter en grande dimension est de s'appuyer sur le principe « un électeur, une force unitaire », ce qui peut typiquement conduire à utiliser la *médiane géométrique*.  
[**Science.**  On the Strategyproofness of the Geometric Median. El-Mahdi El-Mhamdi, Sadegh Farhadkhani, Rachid Guerraoui & Lê-Nguyên Hoang (2021).](https://arxiv.org/abs/2106.02394)

[^licchavi]: Ceci nécessitera certainement de combiner des systèmes de scrutins avec des méthodes d'apprentissage. C'est ce que propose Licchavi.  
[**Science.**  Strategyproof Learning: Building Trustworthy User-Generated Datasets. Sadegh Farhadkhani, Rachid Guerraoui & Lê-Nguyên Hoang (2021)](https://arxiv.org/abs/2106.02398)

Katia marque une nouvelle pause.

### Le fabuleux chantier[^fabuleux-chantier]

[^fabuleux-chantier]: Le fabuleux chantier est le nom d'un livre précédent de Lê Nguyên Hoang, l'un des auteurs de ce livre.  
[**Livre.**  Le fabuleux chantier : Rendre l'intelligence artificielle robustement bénéfique. Lê Nguyên Hoang & El Mahdi El Mhamdi. EDP Sciences (2019).](https://laboutique.edpsciences.fr/produit/1107/9782759824304/Le fabuleux chantier)

Katia change alors de ton, en prenant une voix plus grave et posée.

> Mesdames et messieurs, aujourd'hui est un jour historique, car je vais vous présenter le résultat de deux ans de travail, en collaboration intime avec l'OMESA. Au moment où je parle, une nouvelle plateforme vient d'être mise en ligne, appelée girasol.app[^girasol-tournesol]. Girasol est un site web entièrement Open Source, sous licence libre[^license], qui va coordonner la conception de l'éthique de l'information, en permettant aux utilisateurs de fournir des jugements éthiques, et en utilisant des algorithmes de vote pour construire collaborativement l'éthique de l'information à partir des jugements éthiques des utilisateurs ! Le premier étage d'une éthique démocratique de l'information a été posé !

[^girasol-tournesol]: Girasol n'existe pas, mais il s'agit là en fait clairement d'une référence au projet [tournesol.app](https://tournesol.app) lancé par Lê Nguyên Hoang, l'un des auteurs de ce livre. Le reste du livre décrit finalement la vision global de Tournesol. Vous trouverez beaucoup plus d'informations sur le [wiki de Tournesol](https://wiki.tournesol.app). Il est utile de noter que, surtout pour l'instant, l'objectif de Tournesol est davantage de servir de « microscope des jugements humains », c'est-à-dire d'outils de collecte de données sur ce que les humains jugent éthiquement préférables. En particulier, et entre autres, Tournesol espère ainsi détecter des consensus moraux aujourd'hui difficilement observables, faute de données.

[^license]: Le code de Tournesol est sous [licence AGPL](https://www.gnu.org/licenses/agpl-3.0.en.html), tandis que la base de données publique est sous [license ODbL](https://opendatacommons.org/licenses/odbl/) (à confirmer).

Le public applaudit cette annonce de Katia.

> Je précise que la gouvernance de ce projet est entièrement sous le contrôle de l'OMESA aujourd'hui, et SmartPoop ne sert, et ne servira, que de contributeur bénévole à la base de codes et à la promotion du projet. Tout le code est audité par de nombreuses entités, si bien qu'il est quasiment impossible que le projet soit détourné par une entité maléfique — et ça inclut de potentiels investisseurs de SmartPoop !

Katia marque une nouvelle pause.

> Alors, il y aurait énormément d'autres détails importants à préciser sur ce projet complexe. Mais sachez que, en collaboration avec l'OMESA, nous avons fait de notre mieux pour que chacun de ces détails devienne un sujet de recherche sur lequel travaillent différentes équipes pluridisciplinaires à travers le monde. Ces détails incluent des problématiques comme l'authentification des comptes, pour éviter les faux comptes, en exploitant des mécanismes de Proof of Personhood, et comme garantir le fait que chaque compte authentifié a le même droit de vote que tout autre compte authentifié. Ils incluent aussi l'identification de l'expertise et des excès de confiance des utilisateurs, pour éviter que des théories anti-scientifiques polluent l'éthique de l'information. On peut mentionner aussi l'optimisation de la plateforme par individu, pour que cet individu exploite la manière la plus appropriée pour lui d'exprimer ses jugements éthiques. Ou encore les algorithmes de rectification du biais de participation, pour bien tenir compte des préférences de ceux qui n'ont pas pu participer à Girasol, faute de temps ou d'accès à Internet[^defis-tournesol].

[^defis-tournesol]: Le projet Tournesol soulève énormément de défis, allant de la recherche au développement, en passant par la promotion, par le financement et par les partenariats, entre autres, que les membres de Tournesol ne pourront absolument pas résoudre seuls. *Vous* pouvez aider. Pour en savoir plus, notamment sur l'aspect recherche et développement, nous vous encourageons à lire le *white paper* technique du projet.  
[**Science.**  Tournesol: A quest for a large, secure and trustworthy database of reliable human judgments. Lê-Nguyên Hoang, Louis Faucon, Aidan Jungo, Sergei Volodin, Dalia Papuc, Orfeas Liossatos, Ben Crulis, Mariame Tighanimine, Isabela Constantin, Anastasiia Kucherenko, Alexandre Maurer, Felix Grimberg, Vlad Nitu, Chris Vossen, Sébastien Rouault & El-Mahdi El-Mhamdi (2021).](https://arxiv.org/abs/2107.07334)

Katia s'arrête quelques instants.

> Bref. Il y a plein de défis de recherches remarquables que Girasol devra résoudre, pour ensuite permettre une conception collaborative adéquate de l'éthique de l'information. Girasol est clairement un énorme chantier très difficile à mener. Et c'est aussi un chantier urgent à résoudre.

Katia reprend son souffle pour conclure son discours.

> Mais avant tout, Girasol est un *fabuleux* chantier. Si vous me demandez, il s'agit pour moi du plus fabuleux de tous les chantiers menés par l'humanité, plus grandiose encore que construire des pyramides, plus ambitieux que d'éradiquer des pandémies comme la variole[^variole], et plus spectaculaire que d'envoyer des humains sur la Lune. Girasol, c'est unir toute l'humanité derrière le plus important de tous les aspects de la civilisation humaine : maîtriser collaborativement le flux de l'information[^prochain-livre], et garantir que celui-ci coule comme nous, l'humanité, souhaiterions vraiment qu'il coule, lorsqu'on y réfléchit à tête reposée, avec bienveillance et rigueur. Mesdames et messieurs, ensemble, résolvons l'éthique de l'information[^resoudre-ethique] !

[^variole]: [**Vidéo.**  Le plus grand triomphe de l'humanité. Science4All (2020).](https://www.youtube.com/watch?v=eAzP2QtAAag&list=PLtzmb84AoqRS0SN8VKvAxuGOdcINPRugV&index=9)

[^prochain-livre]: Ceci pourrait d'ailleurs être le sujet d'un prochain livre de Lê Nguyên Hoang... #teaser

[^resoudre-ethique]: [**Vidéo.**  Résolvons l'éthique ensemble !! Science4All (2021).](https://www.youtube.com/watch?v=TgB9pHZ0YPM&list=PLtzmb84AoqRRFcoGQ5p7kqEVQ7deXfYuH&index=4)

À ces mots, le public explose de joie et d'enthousiasme, alors que le vacarme laisse petit à petit place au nom de Katia, lequel est scandé en rythme par tout le stade. Seule sur scène, Katia profite de l'instant, avec un sourire radieux, et salue le public de la main. À ce moment, elle pense à tout ce que SmartPoop a accompli jusque là. Mais aussi et surtout, Katia est incroyablement enthousiasmée par la vision d'une civilisation humaine qui, grâce à Girasol, va enfin prendre le destin de sa civilisation entre ses mains.

Collaborativement.


## Pour aller plus loin

Voilà, le roman est fini !
Vous pouvez revenir au [sommaire](README.md).  
Si vous avez apprécié, pensez à partager et à promouvoir ce roman de science-fiction auprès de vous.
Nous vous en serions très reconnaissants !
